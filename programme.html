<section class="section">
  <h2>Programme (Draft)</h2>
  <p class="muted">
    This is a preliminary agenda to get the ball rolling. Sessions, speakers and timings are indicative and may change
    as the programme is finalised.
  </p>

  <div class="hr"></div>

  <div class="card">
    <h3>09:30 – 10:00 • Welcome</h3>
    <p class="muted small"><b>Lead:</b> Hantao Liu (Cardiff University) <span class="muted">•</span> <b>Format:</b> Opening remarks & overview of the day</p>
    <ul class="muted">
      <li>Welcome and objectives</li>
      <li>How the day is structured</li>
      <li>How we will capture discussion points for the workshop outputs</li>
    </ul>
  </div>

  <div class="hr"></div>

  <h2>Morning session (10:00 – 11:30)</h2>
  <div class="card">
    <h3>Theme: Professional identities with AI</h3>
    <p class="muted">
      A key barrier to AI adoption is fear of the unknown. Psychological and cultural factors—often hard to articulate—
      can shape how frontline staff perceive, engage with, and collaborate on AI-enabled projects.
      This session explores how professional roles and identities may shift when working with AI in practice.
    </p>

    <p class="muted small">
      <b>Chairs / introductions:</b> Christina (City St George’s University of London, TBC) & Susan Shelmerdine (GOSH/UCL)
      <span class="muted">•</span>
      <b>Format:</b> Panel + audience discussion
    </p>

    <p class="muted small"><b>Proposed panel composition (indicative):</b></p>
    <ul class="muted">
      <li>Radiographers (2)</li>
      <li>Radiologists (3)</li>
      <li>Organisational psychologist / business professor (1) – “future of work” perspective</li>
    </ul>

    <p class="muted small"><b>Discussion goals (indicative):</b></p>
    <ul class="muted">
      <li>How do we “future-proof” clinical specialties in the context of AI?</li>
      <li>How do clinicians feel about AI-enabled task redistribution and responsibility?</li>
      <li>What challenges do engineers face when collaborating with clinicians?</li>
      <li>How can we design collaboration and implementation pathways that build trust?</li>
    </ul>

    <p class="muted small"><b>Audience participation:</b> moderated discussion and Q&A.</p>
  </div>

  <div class="hr"></div>

  <div class="card">
    <h3>11:30 – 12:00 • Break</h3>
    <p class="muted">Refreshments and informal networking.</p>
  </div>

  <div class="hr"></div>

  <h2>Late morning session (12:00 – 13:00)</h2>
  <div class="card">
    <h3>Theme: AI ethics as infrastructure</h3>
    <p class="muted">
      Ethical considerations are often treated as “bolt-on” checks. This session explores how ethics can be embedded as
      practical infrastructure—tools, frameworks, and workflows that support responsible and equitable AI integration
      in healthcare.
    </p>

    <p class="muted small">
      <b>Format:</b> Short talks + audience discussion / networking
      <span class="muted">•</span>
      <b>Speaker list (indicative, suggested by KCL):</b>
    </p>

    <ul class="muted">
      <li><b>Rhys Holland</b> (King’s College London, TBC) — fairness awareness tools for responsible AI integration in healthcare</li>
      <li><b>Ciel Burgess</b> (King’s College London, TBC) — frameworks for understanding protected features in AI systems</li>
      <li><b>Raquel Iniesta</b> (King’s College London) — educational tools for patients and clinicians to support responsible AI adoption</li>
    </ul>

    <p class="muted small"><b>Audience interaction:</b> informal discussion and networking around practical ethics and implementation.</p>
  </div>

  <div class="hr"></div>

  <div class="card">
    <h3>13:00 – 14:00 • Lunch</h3>
    <p class="muted">Lunch and networking.</p>
  </div>

  <div class="hr"></div>

  <h2>Afternoon session (14:00 – 15:30)</h2>
  <div class="card">
    <h3>Theme: Translational AI in the real world (TBC)</h3>
    <p class="muted">
      This session will focus on practical, real-world challenges in deploying AI safely and usefully—especially where
      data are limited or cases are rare. Topics may include edge cases, rare diseases, ethical “stress testing”, and
      the small-data problem.
    </p>

    <p class="muted small">
      <b>Format:</b> Invited talks / case examples + discussion (final structure TBC)
      <span class="muted">•</span>
      <b>Speakers:</b> suggestions welcome (Cardiff / GOSH / UCL and beyond)
    </p>

    <p class="muted small"><b>Potential topic areas (indicative):</b></p>
    <ul class="muted">
      <li>Edge cases, rare disease pathways, and clinical safety considerations</li>
      <li>Ethical stress-testing of AI systems</li>
      <li>Small data, dataset shift, and evaluation in practice</li>
      <li>Implementation lessons learned from real deployments</li>
    </ul>
  </div>

  <div class="hr"></div>

  <div class="card">
    <h3>15:30 – 16:00 • Break</h3>
    <p class="muted">Refreshments and informal networking.</p>
  </div>

  <div class="hr"></div>

  <h2>Late afternoon (16:00 – 17:30) (TBC)</h2>
  <div class="card">
    <h3>Workshop output and next steps</h3>
    <p class="muted">
      We will consolidate key discussion points from the day into a short workshop output (e.g. a white paper / statement),
      including barriers to adoption, practical recommendations, and ideas for future funded collaborative projects.
    </p>

    <p class="muted small"><b>Format:</b> facilitated synthesis + group discussion (details TBC)</p>
    <ul class="muted">
      <li>Key barriers and enablers identified across sessions</li>
      <li>Recommendations for responsible translational AI</li>
      <li>Opportunities for follow-on projects and collaborations</li>
    </ul>
  </div>

  <div class="hr"></div>

  <div class="card">
    <h3>17:30 – 18:30 • Close & networking</h3>
    <p class="muted">
      Final remarks and informal networking. (Exact wrap-up timing may be adjusted.)
    </p>
  </div>

  <div class="hr"></div>

  <p class="small muted">
    Note: Attendance is free but registration is required. Capacity limit: up to 100 attendees.
  </p>
</section>
